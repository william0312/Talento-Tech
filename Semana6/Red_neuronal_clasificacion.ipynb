{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1qqkAdmh0Hh9JJp5IivLM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"hLzpL5G7_-sM","executionInfo":{"status":"error","timestamp":1722382584488,"user_tz":300,"elapsed":16767,"user":{"displayName":"William Mora","userId":"14920045433949921219"}},"outputId":"f6630f67-93d8-4851-f538-6c569b310930"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'keras.api._v2.keras.datasets' has no attribute 'load_iris'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a9523d763665>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Descargar y cargar el dataset Iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.datasets' has no attribute 'load_iris'"]}],"source":["import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Descargar y cargar el dataset Iris\n","dataset = tf.keras.datasets.load_iris()\n","X, y = dataset.data, dataset.target\n","\n","# Convertir etiquetas a codificación one-hot\n","onehot_encoder = OneHotEncoder(sparse=False)\n","y_onehot = onehot_encoder.fit_transform(y.reshape(-1, 1))\n","\n","# Dividir en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n","\n","# Normalizar los datos\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Crear el modelo secuencial\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax')\n","])\n","\n","# Compilar el modelo\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Entrenar el modelo\n","history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n","\n","# Evaluar el modelo\n","loss, accuracy = model.evaluate(X_test_scaled, y_test)\n","print(f'Pérdida en el conjunto de prueba: {loss:.4f}')\n","print(f'Precisión en el conjunto de prueba: {accuracy:.4f}')\n","\n","# Graficar la pérdida de entrenamiento y validación\n","plt.figure(figsize=(12, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n","plt.plot(history.history['val_loss'], label='Pérdida de validación')\n","plt.xlabel('Épocas')\n","plt.ylabel('Pérdida')\n","plt.legend()\n","\n","# Graficar la precisión de entrenamiento y validación\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')\n","plt.plot(history.history['val_accuracy'], label='Precisión de validación')\n","plt.xlabel('Épocas')\n","plt.ylabel('Precisión')\n","plt.legend()\n","\n","plt.show()"]}]}